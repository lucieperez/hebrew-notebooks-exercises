{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c39d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: This code can only be used if you have the required dataset, which is not public.\n",
    "# Thus, the original dataset is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5198bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# NB: user needs to install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "A = use(\"etcbc/bhsa\", hoist=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf97512",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_dataset = pd.read_excel(\"verbs_dataset.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ffdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the verb root info column\n",
    "verbs_dataset.info_verbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the different verbs\n",
    "verbs_dataset.info_verbroot.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909107d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the length of the list of verbs\n",
    "verbs_dataset.info_verbroot.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b4946",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_dataset.info_verbroot.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a csv file\n",
    "verbs_dataset.info_verbroot.value_counts().to_csv(\"verbs_counts.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the file\n",
    "pd.read_csv(\"verbs_counts.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a03334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcv stands for book, chapter, verse\n",
    "\n",
    "bcv_verbs = verbs_dataset.groupby(\"info_verbroot\").first().info_refer.values\n",
    "info_verbroot = verbs_dataset.groupby(\"info_verbroot\").first().index\n",
    "#bcv_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b803d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to retrieve book, chapter, name for each verb\n",
    "\n",
    "# retrieve a section book chapter verse from the column refer in the dataset\n",
    "book_names = {\n",
    "    '1Ch':'1_Chronicles',\n",
    "    '1Kgs':'1_Kings',\n",
    "    '1Sam':'1_Samuel',\n",
    "    '2Ch':'2_Chronicles',\n",
    "    '2Kgs':'2_Kings',\n",
    "    '2Sam':'2_Samuel',\n",
    "    'Amos':'Amos',\n",
    "    'Dan':'Daniel',\n",
    "    'Deut':'Deuteronomy',\n",
    "    'Qoh':'Ecclesiastes', \n",
    "    'Est':'Esther',\n",
    "    'Ex':'Exodus',\n",
    "    'Ezek':'Ezekiel',\n",
    "    'Ezra':'Ezra',\n",
    "    'Gen':'Genesis',\n",
    "    'Hab':'Habakkuk', # absent from the dataset\n",
    "    'Hag':'Haggai',\n",
    "    'Hosea':'Hosea', # absent from the dataset\n",
    "    'Isa':'Isaiah',\n",
    "    'Jer':'Jeremiah',\n",
    "    'Job':'Job',\n",
    "    'Joel':'Joel',\n",
    "    'Jonah':'Jonah',\n",
    "    'Josh':'Joshua',\n",
    "    'Jud':'Judges',\n",
    "    'Lam':'Lamentations', # absent from the dataset\n",
    "    'Lev':'Leviticus',\n",
    "    'Mal':'Malachi',\n",
    "    'Micah':'Micah', # absent from the dataset\n",
    "    'Nahum':'Nahum', # absent from the dataset\n",
    "    'Neh':'Nehemiah',\n",
    "    'Num':'Numbers',\n",
    "    'Obad':'Obadiah', # absent from the dataset\n",
    "    'Prov':'Proverbs', # absent from the dataset\n",
    "    'Ps':'Psalms',\n",
    "    'Rut':'Ruth',\n",
    "    'Song_of_songs':'Song_of_songs', # absent from the dataset\n",
    "    'Zech':'Zechariah',\n",
    "    'Zephaniah':'Zephaniah', # absent from the dataset\n",
    "}\n",
    "# sections contains groups of book chapter verse\n",
    "\n",
    "sections = []\n",
    "\n",
    "# separate book from chapter:verse and add the data to the sections list\n",
    "for item in bcv_verbs:\n",
    "    sections.append(item.split(sep=\" \"))\n",
    "\n",
    "# how to split the data into a usable section book, chapter, verse\n",
    "for item in sections:\n",
    "    # split chapter from verse\n",
    "    item[1:] = item[1].split(sep=\":\")\n",
    "    \n",
    "    # transform chapter:verse to integers\n",
    "    item[1] = int(item[1])\n",
    "    item[2] = int(item[2])\n",
    "    \n",
    "    # retrieve the ETCBC book name from the dictionary and replace it in sections\n",
    "    item[0] = book_names[item[0]]\n",
    "    \n",
    "print(sections)\n",
    "\n",
    "# define a function to retrieve the lexeme fronm a section book, chapter, verse\n",
    "def verse_lex(section):\n",
    "    verse = (T.nodeFromSection(section))\n",
    "    return \" \".join([F.lex.v(w) for w in L.d(verse, \"word\")])\n",
    "\n",
    "verses_lexemes = []\n",
    "\n",
    "for section in sections:\n",
    "    verses_lexemes.append(verse_lex(section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e837682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(zip(info_verbroot, sections, verses_lexemes))\n",
    "pd.DataFrame({\"info_verbroot\": info_verbroot, \"bhsa_lex\": [\"\"]*len(info_verbroot), \"sections\": sections, \"verses_lexemes\": verses_lexemes}).to_csv(\"info_verbroot_with_lexemes.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a41a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out the verse_lex function\n",
    "verse_lex(['Isaiah', 6, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f780d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"verb_occ_count_bhsa_lex.csv\", sep=\";\")\n",
    "df\n",
    "\n",
    "# sort the verb_occurrences values in a descending order\n",
    "df[[\"bhsa_lex\", \"verb_occurrences\"]].sort_values(\"verb_occurrences\", ascending=False).to_csv(\"verb_count_etcbc_lex.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with the verbs transcriptions from original dataset linked to the BHSA lexexmes\n",
    "lexemes_dict = dict(zip(df.info_verbroot, df.bhsa_lex))\n",
    "lexemes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5955cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a nex column to the dataset with the BHSA lexemes\n",
    "verbs_dataset.insert(1, \"bhsa_lex\", verbs_dataset.info_verbroot.map(lambda x: lexemes_dict[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e31cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the column info_verbroot\n",
    "info_verbroot = verbs_dataset.pop(\"info_verbroot\")\n",
    "verbs_dataset.insert(2, \"info_verbroot\", info_verbroot)\n",
    "verbs_dataset.to_csv(\"verbs_dataset_modified.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad83632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the values in the book column\n",
    "verbs_dataset.book.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_dataset.gc_prep.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_dataset.gc2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f856610",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(verbs_dataset.bhsa_lex, verbs_dataset.gc_prep).to_csv(\"verbs_and_prep.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(verbs_dataset.bhsa_lex, verbs_dataset.gc2).to_csv(\"verbs_and_hey.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
