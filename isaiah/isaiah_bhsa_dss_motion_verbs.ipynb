{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810412c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from munch import Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd874d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "\n",
    "B = use(\"etcbc/dss\", checkout=\"clone\", version=\"1.8\", hoist=globals())\n",
    "Fdss = F\n",
    "Ldss = L\n",
    "Tdss = T\n",
    "DSS = Munch({\"F\": F, \"L\": L, \"T\": T, \"name\": \"DSS\"})\n",
    "\n",
    "A = use(\"etcbc/bhsa\", hoist=globals())\n",
    "Fmt = F\n",
    "Lmt = L\n",
    "Tmt = T\n",
    "BHSA = Munch({\"F\": F, \"L\": L, \"T\": T, \"name\": \"BHSA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "del F, L, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24823600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mt_isa_df_starter.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing sections (book, chapter, verse) from the DSS\n",
    "# Each section is the key to another dictionary containing: \n",
    "# the name of the scroll (key) and the words of the verse (argument)\n",
    "# NB: all the items in sections are strings\n",
    "\n",
    "# Example\n",
    "# {('Genesis','24','24'): {'1Q1': [1890183, 1890184, ...]},...}\n",
    "\n",
    "dss_sections = {}\n",
    "\n",
    "for word in DSS.F.otype.s(\"word\"):\n",
    "    scroll = DSS.T.scrollName(DSS.L.u(word, \"scroll\")[0])\n",
    "    book = DSS.F.book_etcbc.v(word)\n",
    "    chapter = DSS.F.chapter.v(word)\n",
    "    verse = DSS.F.verse.v(word)\n",
    "    if None in (scroll, book, chapter, verse):\n",
    "        continue\n",
    "    section = (book, chapter, verse)\n",
    "    dss_sections.setdefault(section, {}).setdefault(scroll, []).append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26578658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_words(section, source, scroll=None):\n",
    "    \"\"\"Return the words of a verse found with section, source (and scroll)\"\"\"\n",
    "    if source.name == \"BHSA\":\n",
    "        verse_id = source.T.nodeFromSection(section)\n",
    "        return source.L.d(verse_id, \"word\")\n",
    "    elif source.name == \"DSS\":\n",
    "        section = (section[0], str(section[1]), str(section[2]))\n",
    "        return dss_sections[section][scroll]\n",
    "    else:\n",
    "        assert False, f\"Invalid source {source.name}. The source should be BSHA or DSS. \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a79206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test area\n",
    "\n",
    "#  dss_sections\n",
    "# section_words([\"Isaiah\", \"1\", \"1\"], DSS, \"1Qisaa\")\n",
    "# section_words([\"Isaiah\", 20, 6], BHSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the lexeme from a section (book, chapter, verse)\n",
    "\n",
    "def get_verse_heb(section, source, scroll=None): \n",
    "    \"\"\"Return the verse in Hebrew script\"\"\"\n",
    "    words = section_words(section, source, scroll)\n",
    "    return source.T.text(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecf268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test area\n",
    "# get_verse_heb([\"Isaiah\", 20, 6], DSS, \"1Qisaa\")\n",
    "# get_verse_heb([\"Isaiah\", 20, 6], BHSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f211a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to retrieve information from a dataframe\n",
    "\n",
    "# verse_heb = []\n",
    "\n",
    "### method 1\n",
    "\n",
    "# for book, chapter, verse in sections:\n",
    "#     verse_heb.append(get_verse_heb(book, chapter, verse))\n",
    "    \n",
    "# method 2\n",
    "# for section in sections:\n",
    "#     verse_heb.append(get_verse_heb(*section)) # *list is like calling the function with each element of the list one by one\n",
    "\n",
    "### method 3: running through the columns to get book chapter verse\n",
    "# for section in zip(df.book, df.chapter, df.verse):\n",
    "#     verse_heb.append(get_verse_heb(*section))\n",
    "\n",
    "### method 4: line by line with index (_) \n",
    "# in order to call the function from either BHSA or DSS, use **origin (BHSA or DSS) at the end\n",
    "\n",
    "# for _, row in df.iterrows():\n",
    "#     verse_heb.append(get_verse_heb(row.book, row.chapter, row.verse, **BHSA))\n",
    "    \n",
    "# # add the list as a new column\n",
    "# df[\"verse_heb\"] = verse_heb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06525aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the consonantal representation (g_cons) of any thing\n",
    "\n",
    "def get_g_cons(etcbc_id, source):\n",
    "    \"\"\"Retrieve the consonantal representation for an id of any type\"\"\"\n",
    "    if etcbc_id is None:\n",
    "        return \"\"\n",
    "    elif source.F.otype.v(etcbc_id) == \"word\":\n",
    "        words = [etcbc_id]\n",
    "    else:\n",
    "        words = source.L.d(etcbc_id, \"word\")\n",
    "    return \" \".join([source.F.g_cons.v(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ac4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve verb info\n",
    "\n",
    "def get_verb_id(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Returns the verb's etcbc id\"\"\"\n",
    "    verb = None\n",
    "    for word in section_words(section, source, scroll):\n",
    "        if source.name == \"BHSA\":\n",
    "            if source.F.lex.v(word) == lexeme:\n",
    "                verb = word\n",
    "                break\n",
    "        else:\n",
    "            if source.F.lex_etcbc.v(word) == lexeme:\n",
    "                verb = word\n",
    "                break                           \n",
    "    if verb is None:\n",
    "        print(f\"verb {lexeme} not found in {section, scroll}\")\n",
    "    return verb\n",
    "\n",
    "\n",
    "def get_verb_heb(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Returns the verb in Hebrew script\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    return source.T.text(verb_id)\n",
    "     \n",
    "def get_verb_stem(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Retrieves the verbal stem of a verb\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    if source.name == \"BHSA\":\n",
    "        return source.F.vs.v(verb_id)\n",
    "    else:\n",
    "        return source.F.vs_etcbc.v(verb_id)\n",
    "\n",
    "def get_verb_tense(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Retrieve the verbal tense of a verb\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    if source.name == \"BHSA\":\n",
    "        return source.F.vt.v(verb_id)\n",
    "    else:\n",
    "        return source.F.vt_etcbc.v(verb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ffa9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the phrase and the clause\n",
    "\n",
    "def get_phrase_heb(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Retrieve the phrase in Hebrew script using the get_verb_id function\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    return source.T.text(source.L.u(verb_id, \"phrase\"))\n",
    "        \n",
    "\n",
    "def get_phrase(section, lexeme, source, scroll=None):\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    phrases = source.L.u(verb_id, \"phrase\")\n",
    "    if len(phrases) == 0:\n",
    "        return \"\"\n",
    "    phrase_words = source.L.d(phrases[0], \"word\") \n",
    "    return \" \".join([source.F.g_cons.v(word) for word in phrase_words])\n",
    "\n",
    "def get_clause_heb(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Retrieve the clause in Hebrew script using the get_verb_id function\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    return source.T.text(source.L.u(verb_id, \"clause\"))\n",
    "\n",
    "def get_clause(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Retrieve the clause in ETCBC transcription using the get_verb_id function\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    clauses = source.L.u(verb_id, \"clause\")\n",
    "    if len(clauses) == 0:\n",
    "        return \"\"\n",
    "    clause_words = source.L.d(clauses[0], \"word\") \n",
    "    return \" \".join([source.F.g_cons.v(word) for word in clause_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01386f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing area\n",
    "\n",
    "# get_verb_heb([\"Isaiah\", 6, 6], \"<WP[\", DSS, \"1Qisaa\") \n",
    "\n",
    "# get_phrase_heb([\"Isaiah\", 7, 1], \"<LH[\", DSS, \"1Qisaa\")\n",
    "\n",
    "# get_verb_id([\"Isaiah\", 20, 6], \"NWS[\", DSS, \"1Qisaa\")\n",
    "\n",
    "# get_verb_stem([\"Isaiah\", 6, 6], \"<WP[\", DSS, \"1Qisaa\")\n",
    "\n",
    "# get_verb_tense([\"Isaiah\", 6, 6], \"<WP[\", BHSA)\n",
    "\n",
    "# get_clause_heb([\"Isaiah\", 7, 1], \"<LH[\", DSS, \"1Qisaa\")\n",
    "\n",
    "# get_phrase([\"Isaiah\", 7, 1], \"<LH[\", DSS, \"1Qisaa\")\n",
    "\n",
    "# get_clause([\"Isaiah\", 7, 1], \"<LH[\", DSS, \"1Qisaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve subject and complement(s) of the verb\n",
    "\n",
    "def get_subject(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Find the subject of a verb using the get_verb_id function\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    clauses = source.L.u(verb_id, \"clause\")\n",
    "    if len(clauses) == 0:\n",
    "        return \"\"\n",
    "    clause_phrases = source.L.d(clauses[0], \"phrase\")\n",
    "    subject = None\n",
    "    for phrase in clause_phrases:\n",
    "        if source.F.function.v(phrase) == \"Subj\":\n",
    "            subject = phrase\n",
    "            break\n",
    "    return get_g_cons(subject, source)               \n",
    "    \n",
    "def get_complement(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Find the subject of a verb using the get_verb_id function\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    clauses = source.L.u(verb_id, \"clause\")\n",
    "    if len(clauses) == 0:\n",
    "        return \"\"\n",
    "    clause_phrases = source.L.d(clauses[0], \"phrase\")\n",
    "    complement = None\n",
    "    for phrase in clause_phrases:\n",
    "        if source.F.function.v(phrase) == \"Cmpl\":\n",
    "            complement = phrase\n",
    "            break\n",
    "    return get_g_cons(complement, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ff988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for verse in Hebrew, verb in Hebrew, verbal stem, verbal tense, phrase, clause,\n",
    "\n",
    "dfs = []\n",
    "source_df = df\n",
    "\n",
    "for source, scroll in ((BHSA, None), (DSS, \"1Qisaa\")):\n",
    "    df = source_df.copy()\n",
    "    \n",
    "    if scroll is None:\n",
    "        df[\"scroll\"] = \"MT\"\n",
    "    else:\n",
    "        df[\"scroll\"] = scroll\n",
    "    \n",
    "    #Add the verse in Hebrew script\n",
    "    verse_heb = []\n",
    "    for _, row in df.iterrows():\n",
    "        verse_heb.append(get_verse_heb([row.book, row.chapter, row.verse], source, scroll))\n",
    "\n",
    "    # add the list as a new column\n",
    "    df[\"verse_heb\"] = verse_heb\n",
    "\n",
    "    # Add the verb in Hebrew script\n",
    "    verbs_heb = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_heb.append(get_verb_heb([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    # Add the list as a new column\n",
    "    df[\"verb_heb\"] = verbs_heb\n",
    "\n",
    "    # Add the verbal stem\n",
    "    verbs_stem = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_stem.append(get_verb_stem([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    df[\"verb_stem\"] = verbs_stem\n",
    "\n",
    "    # Add the verbal tense\n",
    "    verbs_tense = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_tense.append(get_verb_tense([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    df[\"verb_tense\"] = verbs_tense\n",
    "\n",
    "    # Add the phrase in Hebrew script\n",
    "    verbs_phrases_heb = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_phrases_heb.append(get_phrase_heb([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    df[\"verb_phrase_heb\"] = verbs_phrases_heb\n",
    "\n",
    "    # Add the phrase (g_cons)\n",
    "    verbs_phrases = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_phrases.append(get_phrase([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    df[\"verb_phrase\"] = verbs_phrases\n",
    "\n",
    "    # Add the clause in Hebrew script\n",
    "    verbs_clauses_heb = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_clauses_heb.append(get_clause_heb([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    df[\"verb_clause_heb\"] = verbs_clauses_heb\n",
    "\n",
    "    # Add the clause (g_cons)\n",
    "    verbs_clauses = []\n",
    "    for _, row in df.iterrows():\n",
    "        verbs_clauses.append(get_clause([row.book, row.chapter, row.verse], row.bhsa_lex, source, scroll))\n",
    "\n",
    "    df[\"verb_clause\"] = verbs_clauses\n",
    "    \n",
    "    # Add the subject in transcription\n",
    "    verb_subjects = []\n",
    "    for _, row in df.iterrows():\n",
    "        verb_subjects.append(get_subject([row.book, row.chapter, row.verse], row.bhsa_lex, BHSA))\n",
    "\n",
    "    df[\"subject\"] = verb_subjects\n",
    "\n",
    "    # Add the subject in transcription\n",
    "    verb_complements = []\n",
    "    for _, row in df.iterrows():\n",
    "        verb_complements.append(get_complement([row.book, row.chapter, row.verse], row.bhsa_lex, BHSA))\n",
    "\n",
    "    df[\"complement\"] = verb_complements\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the final_df\n",
    "\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the columns\n",
    "final_df = final_df[[\"bhsa_lex\", \"book\", \"chapter\", \"verse\", \"scroll\", \"verb_heb\", \"verse_heb\", \"verb_stem\", \"verb_tense\", \"verb_phrase_heb\", \"verb_phrase\", \"verb_clause_heb\", \"verb_clause\", \"subject\", \"complement\"]]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe306f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing area\n",
    "# get_verb_id([\"Isaiah\", 7, 1], \"<LH[\", DSS, \"1Qisaa\")\n",
    "# get_subject(\"Genesis\", 8, 3, \"HLK[\", **BHSA)\n",
    "# get_g_cons(3592)\n",
    "# get_complement([\"Genesis\", 8, 3], \"HLK[\", BHSA)\n",
    "# get_subject([\"Isaiah\", 7, 1], \"<LH[\", DSS, \"1Qisaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3927199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "\n",
    "final_df.to_csv(\"mt_and_dss_isaiah_df.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve information about the complement(s)\n",
    "\n",
    "# create a function to distinguish complements with/without prepositions\n",
    "\n",
    "verb_complements = {}\n",
    "\n",
    "def get_cmpl_type(section, lexeme, source, scroll=None):\n",
    "    \"\"\"Find the subject of a verb using the get_verb_id function\"\"\"\n",
    "    verb_id = get_verb_id(section, lexeme, source, scroll)\n",
    "    if verb_id is None:\n",
    "        return \"\"\n",
    "    clauses = source.L.u(verb_id, \"clause\")\n",
    "    if len(clauses) == 0:\n",
    "        return \"\"\n",
    "    clause_phrases = source.L.d(clauses[0], \"phrase\")\n",
    "    complement = None\n",
    "    for phrase in clause_phrases:\n",
    "        if source.F.function.v(phrase) == \"Cmpl\":\n",
    "            complement = phrase\n",
    "            complement_words = source.L.d(phrase, \"word\")\n",
    "            preposition = None\n",
    "            for word in complement_words:\n",
    "                if source.F.sp.v(word) == \"prep\":\n",
    "                    preposition = word\n",
    "                    verb_complements[get_g_cons(verb_id, source)] = (get_g_cons(complement, source),get_g_cons(preposition, source))\n",
    "                    break\n",
    "    return verb_complements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fadd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cmpl_type([\"Isaiah\", 7, 6], \"<LH[\", BHSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_complement([\"Isaiah\", 7, 6], \"<LH[\", BHSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in Fall():\n",
    "    print(feature, getattr(BHSA.F, feature).v(214369))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
